### Task 0:
This is the First task: Translate each source language to the target language specified

Action Steps:
Download the attached Excel sheet.

Open it in Google Sheets by uploading it to your Google Drive.

Rename the document using this format:
Your Name - Language (e.g., Amaka - Yoruba).

Begin working on your translation task in your assigned section.

Once ready, send me the link to your Google Sheet (make sure the sharing settings allow access - editor access).

If you have any questions or run into challenges, feel free to reach out. I’m here to support you throughout the process.

Looking forward to your contributions!


### Task 1:
**The first research to be done**
- How Translation Models Work
Explore how machine translation models (like Google Translate) are trained.

Understand concepts like sequence-to-sequence models, transformers, and language modeling.

_Make a detailed report on your findings and submit on Friday, 2/05/2025_
This will make you get familiar with what the project entails.



### Task 2:
Hi Team,

Following up on our recent meeting and the translation work, I’d like to assign a few practical tasks to help deepen your understanding of the data pipeline and its real-world application in NLP projects.
Please find the task breakdown below:

 1. Web Scraping
•	Choose a news site or blog that supports any Nigerian language or English (e.g., BBC, Vanguard, The Guardian Nigeria).
•	Scrape at least 100 paragraphs of text from a selected category (e.g., Health, Politics, Technology).
•	Save your data in a CSV file with columns: Text, Category, Source.
 2. Data Pre-processing
•	Clean the scraped data by:
o	Removing punctuation, extra white spaces, and special characters.
o	Lowercasing all text.
o	Removing stop words (you can use libraries like NLTK or spaCy).
•	Save the cleaned data in a new column called Cleaned_Text.

Deliverable:
•	Upload your final CSV file to Google Drive and send me the link.
•	Please submit by Friday, 9/05/2025.
This task will help you understand how raw data is collected, cleaned, and prepared for analysis or modeling. Feel free to ask questions if you need clarification or help with any step.

Thanks, and happy coding!

Best regards,
Amaka

### Task 3:
The Task for Next Week
SENTIMENT ANALYSIS

Do a sentiment analysis on the text data you've gotten after preprocessing your data.

Submission of this task is on Friday 16th May, 2025.

### Task 4:
Next Task
Research on Tokenizer Models in NLP (Natural Language Processing)
You might be called upon to present your findings, so please make sure it's done properly.

For now, kindly finish up on the tasks you haven't done

### Task 5:
Hi Team,

Great work so far on your research tasks.

Next Task:

Please ensure that you implement the research you've done on the tokenizer models in NLP on the dataset you have on ground. It's important that your findings are not just theoretical but practically applied as well. So please make sure your work is well-documented, and clearly structured.

Lastly, if you have any pending tasks, kindly finish them up as soon as possible.

Thank you and keep up the good work.

### Task 6:
Task for the Week for Translation Team
Parallel Corpus Collection for Translation Models
Week Objective:

Understand the importance of parallel (aligned) corpora in building machine translation systems by actively collecting, processing, and documenting bilingual datasets.
Task Description:

Your task for the week is to search for, collect, and prepare bilingual (parallel) text datasets in one of the following language pairs:
•	English – Igbo
•	English – Hausa 
•	English – Yoruba

Deliverables:
By the end of the week, submit the following:
1.	Parallel Corpus File:
•	Format: CSV format
•	Structure: Two aligned columns — one for English and one for the target language (Hausa, Igbo and Yoruba).
•	Minimum: 3000 sentence pairs 
2.	Documentation Report (1–2 pages):
•	Where and how you found the data (sources).
•	Any cleaning or formatting steps you took.
•	Challenges you faced during the collection/alignment process.
•	Reflection on why parallel corpora are important in machine translation.

Hints and Resources:
•	Consider sources like Global Voices, or TED Talks with subtitles.
•	Tools that might help: BeautifulSoup (for web scraping), Google Sheets or Excel (for manual alignment).
•	Ensure sentence-level alignment as best as possible, avoid just collecting blocks of text.

Learning Goals:
•	Gain hands-on experience in collecting real-world data.
•	Understand how aligned bilingual datasets support the training of neural machine translation models.
•	Develop basic skills in text processing and documentation.
