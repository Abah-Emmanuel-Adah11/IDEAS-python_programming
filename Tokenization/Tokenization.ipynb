{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cfe193e-657e-4a58-9b2b-82754d484dfc",
   "metadata": {},
   "source": [
    "### Step 1: Install the librabry required for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a53f78-c299-4620-9fb6-924648443a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\homepc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b6dea-b39e-44ae-b941-92903b94792d",
   "metadata": {},
   "source": [
    "### Step 2: Download NLTK Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f74d42-c6e5-4a34-9cdc-5e8657f04d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HomePC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HomePC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  #Used for tokenization\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef7ac6-5d9b-45d5-9ea3-540873d3250e",
   "metadata": {},
   "source": [
    "### Step 3: Load the CSV File contianing the data to be Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5351bf6-7fe6-495f-a5b2-89510384c130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Source</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris Saint-Germain clinched a place in the Ch...</td>\n",
       "      <td>paris saintgermain clinched a place champions ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruiz crashed in a shot from the edge of the ar...</td>\n",
       "      <td>ruiz crashed shot edge area 27th minute parc d...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Already leading in the tie after Ousmane Dembe...</td>\n",
       "      <td>already leading tie ousmane dembeles goal last...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>However, Hakimi put the tie beyond Arsenal whe...</td>\n",
       "      <td>however hakimi put tie beyond arsenal scored 7...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PSG advance to a showdown in Munich on May 31 ...</td>\n",
       "      <td>psg advance showdown munich may 31 inter milan...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Paris Saint-Germain clinched a place in the Ch...   \n",
       "1  Ruiz crashed in a shot from the edge of the ar...   \n",
       "2  Already leading in the tie after Ousmane Dembe...   \n",
       "3  However, Hakimi put the tie beyond Arsenal whe...   \n",
       "4  PSG advance to a showdown in Munich on May 31 ...   \n",
       "\n",
       "                                        Cleaned_Text Category  \\\n",
       "0  paris saintgermain clinched a place champions ...   Sports   \n",
       "1  ruiz crashed shot edge area 27th minute parc d...   Sports   \n",
       "2  already leading tie ousmane dembeles goal last...   Sports   \n",
       "3  however hakimi put tie beyond arsenal scored 7...   Sports   \n",
       "4  psg advance showdown munich may 31 inter milan...   Sports   \n",
       "\n",
       "                                              Source Sentiment  \n",
       "0  https://www.vanguardngr.com/2025/05/psg-beat-a...  Positive  \n",
       "1  https://www.vanguardngr.com/2025/05/psg-beat-a...  Negative  \n",
       "2  https://www.vanguardngr.com/2025/05/psg-beat-a...  Positive  \n",
       "3  https://www.vanguardngr.com/2025/05/psg-beat-a...   Neutral  \n",
       "4  https://www.vanguardngr.com/2025/05/psg-beat-a...   Neutral  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Sentiment_Analysis_Results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756efbe-8a7f-417b-a415-b0bb975ef1f2",
   "metadata": {},
   "source": [
    "### Step 4: Inspect the Text Column\n",
    "**Identify the name of the column containing text, this to ensure that we know what text column of our dataset, to be used for Tokenization**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20ddcdfc-7020-4e14-ae18-189c70286d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text', 'Cleaned_Text', 'Category', 'Source', 'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  # Check column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce8a74-6961-435e-a26b-663f2b9fbe86",
   "metadata": {},
   "source": [
    "### Step 5: Tokenize the Text\n",
    "From the step above we will be using the column \"Cleaned_Text\" for our Tokenization and we will using ***Word based tokenizer*** others are, ***character or letter tokenizer*** and ***sub-word tokenizer***. Finally, the result from the tokenization will be saved in a new column called ***\"Token\"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "276451c2-97ed-4ce1-925b-f9d195949beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Source</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris Saint-Germain clinched a place in the Ch...</td>\n",
       "      <td>paris saintgermain clinched a place champions ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[paris, saintgermain, clinched, a, place, cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruiz crashed in a shot from the edge of the ar...</td>\n",
       "      <td>ruiz crashed shot edge area 27th minute parc d...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[ruiz, crashed, shot, edge, area, 27th, minute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Already leading in the tie after Ousmane Dembe...</td>\n",
       "      <td>already leading tie ousmane dembeles goal last...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[already, leading, tie, ousmane, dembeles, goa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>However, Hakimi put the tie beyond Arsenal whe...</td>\n",
       "      <td>however hakimi put tie beyond arsenal scored 7...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[however, hakimi, put, tie, beyond, arsenal, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PSG advance to a showdown in Munich on May 31 ...</td>\n",
       "      <td>psg advance showdown munich may 31 inter milan...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>https://www.vanguardngr.com/2025/05/psg-beat-a...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[psg, advance, showdown, munich, may, 31, inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Paris Saint-Germain clinched a place in the Ch...   \n",
       "1  Ruiz crashed in a shot from the edge of the ar...   \n",
       "2  Already leading in the tie after Ousmane Dembe...   \n",
       "3  However, Hakimi put the tie beyond Arsenal whe...   \n",
       "4  PSG advance to a showdown in Munich on May 31 ...   \n",
       "\n",
       "                                        Cleaned_Text Category  \\\n",
       "0  paris saintgermain clinched a place champions ...   Sports   \n",
       "1  ruiz crashed shot edge area 27th minute parc d...   Sports   \n",
       "2  already leading tie ousmane dembeles goal last...   Sports   \n",
       "3  however hakimi put tie beyond arsenal scored 7...   Sports   \n",
       "4  psg advance showdown munich may 31 inter milan...   Sports   \n",
       "\n",
       "                                              Source Sentiment  \\\n",
       "0  https://www.vanguardngr.com/2025/05/psg-beat-a...  Positive   \n",
       "1  https://www.vanguardngr.com/2025/05/psg-beat-a...  Negative   \n",
       "2  https://www.vanguardngr.com/2025/05/psg-beat-a...  Positive   \n",
       "3  https://www.vanguardngr.com/2025/05/psg-beat-a...   Neutral   \n",
       "4  https://www.vanguardngr.com/2025/05/psg-beat-a...   Neutral   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [paris, saintgermain, clinched, a, place, cham...  \n",
       "1  [ruiz, crashed, shot, edge, area, 27th, minute...  \n",
       "2  [already, leading, tie, ousmane, dembeles, goa...  \n",
       "3  [however, hakimi, put, tie, beyond, arsenal, s...  \n",
       "4  [psg, advance, showdown, munich, may, 31, inte...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Assuming the text column is named \"Cleaned_Text\"\n",
    "df['Tokens'] = df['Cleaned_Text'].astype(str).apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a61c0f-12e0-4525-8df0-27cc81d64b4d",
   "metadata": {},
   "source": [
    "### Step 6. (Optional) Save to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a9685d8-d74d-4b90-9afe-6ef6af06add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Tokenized_Output.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
